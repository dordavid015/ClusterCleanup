apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: cluster-cleanup-{{ randAlphaNum 7 | lower }}
  namespace: default
spec:
  entrypoint: cleanup-tasks
  templates:
  - name: cleanup-tasks
    steps:
    steps:
      - - name: cleanup-deployments
          when: "{{ .Values.cleanup.deployments }}"
          template: cleanup-deployments
      - - name: cleanup-statefulsets
          when: "{{ .Values.cleanup.statefulsets }}"
          template: cleanup-statefulsets
      - - name: cleanup-scale-failed-objects-to-zero
          when: "{{ .Values.cleanup.cleanupScaleFailedObjectsToZero }}"
          template: cleanup-scale-failed-objects-to-zero
      - - name: cleanup-services
          when: "{{ .Values.cleanup.services }}"
          template: cleanup-services
      - - name: cleanup-complete-pods
          when: "{{ .Values.cleanup.completePods }}"
          template: cleanup-complete-pods
      - - name: cleanup-available-pvs
          when: "{{ .Values.cleanup.availablePvs }}"
          template: cleanup-available-pvs
      - - name: cleanup-empty-namespaces
          when: "{{ .Values.cleanup.emptyNamespaces }}"
          template: cleanup-empty-namespaces
      - - name: cleanup-unbound-pvcs
          when: "{{ .Values.cleanup.unboundPvcs }}"
          template: cleanup-unbound-pvcs
      - - name: cleanup-empty-ingresses
          when: "{{ .Values.cleanup.emptyIngresses }}"
          template: cleanup-empty-ingresses
      - - name: print-report
          when: "{{ .Values.cleanup.printReport }}"
          template: print-report
          arguments:
            parameters:
            - name: cleanup-deployments
              value: "{{ `{{ steps.cleanup-deployments.outputs.parameters.cleanup-deployments }}` }}"
            - name: cleanup-statefulsets
              value: "{{ `{{ steps.cleanup-statefulsets.outputs.parameters.cleanup-statefulsets }}` }}"
            - name: cleanup-services
              value: "{{ `{{ steps.cleanup-services.outputs.parameters.cleanup-services }}` }}"
            - name: cleanup-complete-pods
              value: "{{ `{{ steps.cleanup-complete-pods.outputs.parameters.cleanup-complete-pods }}` }}"
            - name: cleanup-scale-failed-objects-to-zero
              value: "{{ `{{ steps.cleanup-scale-failed-objects-to-zero.outputs.parameters.cleanup-scale-failed-objects-to-zero }}` }}"
            - name: cleanup-available-pvs
              value: "{{ `{{ steps.cleanup-available-pvs.outputs.parameters.cleanup-available-pvs}}` }}"
            - name: cleanup-empty-namespaces
              value: "{{ `{{ steps.cleanup-empty-namespaces.outputs.parameters.cleanup-empty-namespaces }}` }}"
            - name: cleanup-unbound-pvcs
              value: "{{ `{{ steps.cleanup-unbound-pvcs.outputs.parameters.cleanup-unbound-pvcs }}` }}"
            - name: cleanup-empty-ingresses
              value: "{{ `{{ steps.cleanup-empty-ingresses.outputs.parameters.cleanup-empty-ingresses }}` }}"

  - name: cleanup-deployments
    outputs:
        parameters:
        - name: cleanup-deployments  
          valueFrom:
            path: /tmp/result.txt
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        #!/bin/sh
        cd /tmp
        touch result.txt
        echo "Cleaning up Deployments scaled to 0..."
        count=0
        for namespace in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
          for deployment in $(kubectl get deployments -n $namespace -o jsonpath='{.items[?(@.spec.replicas==0)].metadata.name}'); do
            kubectl delete deployment $deployment -n $namespace {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
            count=$((count + 1))
          done
        done
        echo "Deleted $count Deployments with 0 replicas.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt

  - name: cleanup-statefulsets
    outputs:
        parameters:
        - name: cleanup-statefulsets  
          valueFrom:
            path: /tmp/result.txt
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        #!/bin/sh
        cd /tmp
        touch result.txt
        echo "Cleaning up statefulsets scaled to 0..."
        count=0
        for namespace in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
          for statefulset in $(kubectl get statefulsets -n $namespace -o jsonpath='{.items[?(@.spec.replicas==0)].metadata.name}'); do
            kubectl delete statefulsets $statefulset -n $namespace {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
            count=$((count + 1))
          done
        done
        echo "Deleted $count statefulsets with 0 replicas.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt

  - name: cleanup-scale-failed-objects-to-zero
    outputs:
        parameters:
        - name: cleanup-scale-failed-objects-to-zero 
          valueFrom:
            path: /tmp/result.txt
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        #!/bin/sh
        cd /tmp
        touch result.txt
        echo "Checking CrashLoopBackOff pods older than a week..."
        count=0
        current_date=$(date +%s)

        for namespace in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
          for pod in $(kubectl get pods -n $namespace -o json | jq -r '.items[] | select(.status.containerStatuses[0].state.waiting.reason == "CrashLoopBackOff" or .status.containerStatuses[0].state.waiting.reason == "ImagePullBackOff") | .metadata.name'); do
            creation_timestamp=$(kubectl get pod $pod -n $namespace -o jsonpath='{.metadata.creationTimestamp}')
            creation_date=$(date -d "$creation_timestamp" +%s)
            age_days=$(( (current_date - creation_date) / 86400 ))

            if [ "$age_days" -gt 7 ]; then
              echo "Pod $pod in namespace $namespace is in CrashLoopBackOff for more than a week ($age_days days)."
              owner_kind=$(kubectl get pod $pod -n $namespace -o jsonpath='{.metadata.ownerReferences[0].kind}')
              owner_name=$(kubectl get pod $pod -n $namespace -o jsonpath='{.metadata.ownerReferences[0].name}')
              if [ "$owner_kind" = "ReplicaSet" ]; then
                deployment_name=$(kubectl get replicaset $owner_name -n $namespace -o jsonpath='{.metadata.ownerReferences[0].name}')
                if [ -n "$deployment_name" ]; then
                  echo "Scaling deployment $deployment_name to 0 replicas in namespace $namespace."
                  kubectl scale deployment $deployment_name -n $namespace --replicas=0 {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
                  count=$((count + 1))
                fi
              elif [ "$owner_kind" = "StatefulSet" ] || [ "$owner_kind" = "DaemonSet" ]; then
                echo "Scaling $owner_kind $owner_name to 0 replicas in namespace $namespace."
                kubectl scale $owner_kind $owner_name -n $namespace --replicas=0
                count=$((count + 1))
              fi
            else
              echo "Pod $pod in namespace $namespace has been in CrashLoopBackOff for $age_days days, skipping."
            fi
          done
        done
        echo "Scaled down $count owners of CrashLoopBackOff pods older than a week.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt

  - name: cleanup-services
    outputs:
        parameters:
        - name: cleanup-services  
          valueFrom:
            path: /tmp/result.txt
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        #!/bin/sh
        cd /tmp
        touch result.txt
        echo "Scanning for Services without Endpoints..."
        count=0
        for namespace in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
          for service in $(kubectl get svc -n $namespace -o jsonpath='{.items[*].metadata.name}'); do
            endpoints=$(kubectl get endpoints $service -n $namespace -o jsonpath='{.subsets}' 2>/dev/null)
            if [ -z "$endpoints" ]; then
              kubectl delete svc $service -n $namespace {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
              count=$((count + 1))
            fi
          done
        done
        echo "Deleted $count Services without Endpoints.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt

  - name: cleanup-complete-pods
    outputs:
        parameters:
        - name: cleanup-complete-pods  
          valueFrom:
            path: /tmp/result.txt
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        #!/bin/sh
        cd /tmp
        touch result.txt
        echo "Cleaning up completed Pods..."
        count=0
        for namespace in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
          for pod in $(kubectl get pods -n $namespace --field-selector=status.phase=Succeeded -o jsonpath='{.items[*].metadata.name}'); do
            kubectl delete pod $pod -n $namespace {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
            count=$((count + 1))
          done
        done
        echo "Deleted $count completed Pods.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt

  - name: cleanup-available-pvs
    outputs:
        parameters:
        - name: cleanup-available-pvs  
          valueFrom:
            path: /tmp/result.txt    
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        #!/bin/sh
        cd /tmp
        touch result.txt
        echo "Cleaning up available Persistent Volumes (PVs)..."
        count=0
        for pv in $(kubectl get pv --no-headers | awk '$5 == "Available" {print $1}'); do
          kubectl delete pv $pv {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
          count=$((count + 1))
        done
        echo "Deleted $count available Persistent Volumes.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt

  - name: cleanup-empty-namespaces
    outputs:
        parameters:
        - name: cleanup-empty-namespaces  
          valueFrom:
            path: /tmp/result.txt
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        #!/bin/sh
        cd /tmp
        touch result.txt
        echo "Cleaning up empty namespaces..."
        count=0
        for namespace in $(kubectl get namespaces --no-headers | awk '{print $1}'); do
          deploy_count=$(kubectl get deployments -n $namespace --no-headers 2>/dev/null | wc -l)
          pod_count=$(kubectl get pods -n $namespace --no-headers 2>/dev/null | wc -l)
          svc_count=$(kubectl get svc -n $namespace --no-headers 2>/dev/null | wc -l)
          if [ "$deploy_count" -eq 0 ] && [ "$pod_count" -eq 0 ] && [ "$svc_count" -eq 0 ]; then
            kubectl delete namespace $namespace {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
            count=$((count + 1))
          fi
        done
        echo "Deleted $count empty namespaces.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt

  - name: cleanup-unbound-pvcs 
    outputs:
        parameters:
        - name: cleanup-unbound-pvcs 
          valueFrom:
            path: /tmp/result.txt
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        #!/bin/sh
        cd /tmp
        touch result.txt
        echo "Cleaning up unbound PVCs..."
        count=0
        for pvc in $(kubectl get pvc --no-headers | awk '$2 == "Pending" {print $1}'); do
          kubectl delete pvc $pvc {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
          count=$((count + 1))
        done
        echo "Deleted $count unbound PVCs.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt


  - name: cleanup-empty-ingresses 
    outputs:
        parameters:
        - name: cleanup-empty-ingresses 
          valueFrom:
            path: /tmp/result.txt
    script:
      image: bitnami/kubectl:latest
      command:
        - sh
      source: |
        echo "Starting cleanup of Ingresses referencing non-existent Services in each namespace..."
        count=0
        # Get all namespaces
        namespaces=$(kubectl get namespaces --no-headers -o custom-columns=":metadata.name")
        if [ -z "$namespaces" ]; then
            echo "No namespaces found."
            exit 1
        fi

        for namespace in $namespaces; do
            echo "Checking Ingresses in Namespace: $namespace"

            # Get all Ingress names in the current namespace
            ingresses=$(kubectl get ingress -n "$namespace" --no-headers -o custom-columns=":metadata.name")
            if [ -z "$ingresses" ]; then
                echo "No Ingresses found in Namespace: $namespace."
            else
                for ingress in $ingresses; do
                    echo "  Checking Ingress: $ingress"

                    # Get the Services referenced by this Ingress
                    services=$(kubectl get ingress "$ingress" -n "$namespace" -o custom-columns=":spec.rules[*].http.paths[*].backend.service.name")

                    if [ -n "$services" ]; then
                        for service in $services; do
                            echo "    Validating Service: $service"
 
                            # Check if service exists
                            service_check=$(kubectl get service "$service" -n "$namespace" --ignore-not-found)
                            if [ -z "$service_check" ]; then
                                echo "    Service $service does not exist. Deleting Ingress: $ingress"
                                kubectl delete ingress "$ingress" -n "$namespace" {{ if .Values.cleanup.dryRun }}--dry-run=client{{ end }}
                                count=$((count + 1))
                                break  # Stop checking other services for this Ingress
                            fi
                        done
                    else
                        echo "Ingress $ingress in Namespace $namespace does not reference any Services."
                    fi
                done
            fi
        done
        echo "Deleted $count empty ingress resources.{{ if .Values.cleanup.dryRun }} Operation was performed in dry-run mode.{{ end }}" > /tmp/result.txt


  - name: print-report
    inputs:
      parameters:
      - name: cleanup-deployments
      - name: cleanup-statefulsets
      - name: cleanup-services
      - name: cleanup-complete-pods
      - name: cleanup-scale-failed-objects-to-zero
      - name: cleanup-available-pvs
      - name: cleanup-empty-namespaces
      - name: cleanup-unbound-pvcs
      - name: cleanup-empty-ingresses
    script:
      image: busybox
      command: [sh, -c]
      source: |
        echo "Cleanup Deployments: {{ `{{ inputs.parameters.cleanup-deployments }}` }}"
        echo "Cleanup statefulsets: {{ `{{ inputs.parameters.cleanup-statefulsets }}` }}"
        echo "Cleanup Services: {{ `{{ inputs.parameters.cleanup-services }}` }}"
        echo "Cleanup Complete Pods: {{ `{{ inputs.parameters.cleanup-complete-pods }}` }}"
        echo "Cleanup Failed objects: {{ `{{ inputs.parameters.cleanup-scale-failed-objects-to-zero }}` }}"
        echo "Cleanup Available PVs: {{ `{{ inputs.parameters.cleanup-available-pvs }}` }}"
        echo "Cleanup Empty Namespaces: {{ `{{ inputs.parameters.cleanup-empty-namespaces }}` }}"
        echo "Cleanup Unbound PVCs: {{ `{{ inputs.parameters.cleanup-unbound-pvcs }}` }}"
        echo "Cleanup Empty Ingress Resources: {{ `{{ inputs.parameters.cleanup-empty-ingresses }}` }}"
